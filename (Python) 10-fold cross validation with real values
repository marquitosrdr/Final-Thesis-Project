import os
os.chdir("C:\\Users\\Marcos Rusinol\\Desktop\\dataset")
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from keras import models
from keras import layers
from sklearn.metrics import confusion_matrix

# Importing the dataset
dataset = pd.read_csv('datasetcompletepy.csv',sep=';')

#BALANCING DATASET
datasetdef = dataset.loc[dataset.Default == 1]
datasetnodef = dataset.loc[dataset.Default == 0]
datasetnodef = datasetnodef.sample(79768)
dataset = pd.concat([datasetdef, datasetnodef])

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_X_1 = LabelEncoder()
dataset['State'] = labelencoder_X_1.fit_transform(dataset['State'])
labelencoder_X_2 = LabelEncoder()
dataset['BankState'] = labelencoder_X_2.fit_transform(dataset['BankState'])
labelencoder_X_3 = LabelEncoder()
dataset['UrbanRural'] = labelencoder_X_3.fit_transform(dataset['UrbanRural'])
labelencoder_X_4 = LabelEncoder()
dataset['RevLineCr'] = labelencoder_X_4.fit_transform(dataset['RevLineCr'])
labelencoder_X_5 = LabelEncoder()
dataset['LowDoc'] = labelencoder_X_5.fit_transform(dataset['LowDoc'])

onehotencoder_0 = OneHotEncoder(categorical_features = [1,2,4])
dataset = onehotencoder_0.fit_transform(dataset).toarray()


#dataset_part_1 = dataset.iloc[1:34347,:]
#dataset_part_2 = dataset.iloc[34347:68692,:]
#dataset_part_3 = dataset.iloc[68693:103038,:]
#dataset_part_4 = dataset.iloc[103039:137384,:]
#dataset_part_5 = dataset.iloc[137385:171730,:]
#dataset_part_6 = dataset.iloc[171731:206076,:]
#dataset_part_7 = dataset.iloc[206077:240422,:]
#dataset_part_8 = dataset.iloc[240423:274768,:]
#dataset_part_9 = dataset.iloc[274769:309114,:]
#dataset_part_10 = dataset.iloc[309115:343467,:]

dataset_part_1 = dataset[1:15953,:]
dataset_part_2 = dataset[15954:31906,:]
dataset_part_3 = dataset[31907:47859,:]
dataset_part_4 = dataset[47860:63812,:]
dataset_part_5 = dataset[63813:79765,:]
dataset_part_6 = dataset[79766:95718,:]
dataset_part_7 = dataset[95719:111671,:]
dataset_part_8 = dataset[111672:127624,:]
dataset_part_9 = dataset[127625:143577,:]
dataset_part_10 = dataset[143578:159530,:]

k1_train = np.concatenate([dataset_part_2,dataset_part_3,dataset_part_4,dataset_part_5,dataset_part_6,dataset_part_7,
                      dataset_part_8,dataset_part_9,dataset_part_10])
X1_train = k1_train[:, 1:16]
y1_train = k1_train[:, 0]
k1_test = dataset_part_1
X1_test = k1_test[:, 1:16]
y1_test = k1_test[:, 0]

k2_train = np.concatenate([dataset_part_1,dataset_part_3,dataset_part_4,dataset_part_5,dataset_part_6,dataset_part_7,
                      dataset_part_8,dataset_part_9,dataset_part_10])
X2_train = k2_train[:, 1:16]
y2_train = k2_train[:, 0]
k2_test = dataset_part_2
X2_test = k2_test[:, 1:16]
y2_test = k2_test[:, 0]

k3_train = np.concatenate([dataset_part_1,dataset_part_2,dataset_part_4,dataset_part_5,dataset_part_6,dataset_part_7,
                      dataset_part_8,dataset_part_9,dataset_part_10])
X3_train = k3_train[:, 1:16]
y3_train = k3_train[:, 0]
k3_test = dataset_part_3
X3_test = k3_test[:, 1:16]
y3_test = k3_test[:, 0]

k4_train = np.concatenate([dataset_part_1,dataset_part_2,dataset_part_3,dataset_part_5,dataset_part_6,dataset_part_7,
                      dataset_part_8,dataset_part_9,dataset_part_10])
X4_train = k4_train[:, 1:16]
y4_train = k4_train[:, 0]
k4_test = dataset_part_4
X4_test = k4_test[:, 1:16]
y4_test = k4_test[:, 0]

k5_train = np.concatenate([dataset_part_1,dataset_part_2,dataset_part_3,dataset_part_4,dataset_part_6,dataset_part_7,
                      dataset_part_8,dataset_part_9,dataset_part_10])
X5_train = k5_train[:, 1:16]
y5_train = k5_train[:, 0]
k5_test = dataset_part_5
X5_test = k5_test[:, 1:16]
y5_test = k5_test[:, 0]

k6_train = np.concatenate([dataset_part_1,dataset_part_2,dataset_part_3,dataset_part_4,dataset_part_5,dataset_part_7,
                      dataset_part_8,dataset_part_9,dataset_part_10])
X6_train = k6_train[:, 1:16]
y6_train = k6_train[:, 0]
k6_test = dataset_part_6
X6_test = k6_test[:, 1:16]
y6_test = k6_test[:, 0]

k7_train = np.concatenate([dataset_part_1,dataset_part_2,dataset_part_3,dataset_part_4,dataset_part_5,dataset_part_6,
                      dataset_part_8,dataset_part_9,dataset_part_10])
X7_train = k7_train[:, 1:16]
y7_train = k7_train[:, 0]
k7_test = dataset_part_7
X7_test = k7_test[:, 1:16]
y7_test = k7_test[:, 0]

k8_train = np.concatenate([dataset_part_1,dataset_part_2,dataset_part_3,dataset_part_4,dataset_part_5,dataset_part_6,
                      dataset_part_7,dataset_part_9,dataset_part_10])
X8_train = k8_train[:, 1:16]
y8_train = k8_train[:, 0]
k8_test = dataset_part_8
X8_test = k8_test[:, 1:16]
y8_test = k8_test[:, 0]

k9_train = np.concatenate([dataset_part_1,dataset_part_2,dataset_part_3,dataset_part_4,dataset_part_5,dataset_part_6,
                      dataset_part_7,dataset_part_8,dataset_part_10])
X9_train = k9_train[:, 1:16]
y9_train = k9_train[:, 0]
k9_test = dataset_part_9
X9_test = k9_test[:, 1:16]
y9_test = k9_test[:, 0]

k10_train = np.concatenate([dataset_part_1,dataset_part_2,dataset_part_3,dataset_part_4,dataset_part_5,dataset_part_6,
                       dataset_part_7,dataset_part_8,dataset_part_9])
X10_train = k10_train[:, 1:16]
y10_train = k10_train[:, 0]
k10_test = dataset_part_10
X10_test = k10_test[:, 1:16]
y10_test = k10_test[:, 0]

X_train_cross = [X1_train,X2_train,X3_train,X4_train,X5_train,X6_train,X7_train,X8_train,X9_train,X10_train]
y_train_cross = [y1_train,y2_train,y3_train,y4_train,y5_train,y6_train,y7_train,y8_train,y9_train,y10_train]
X_test_cross = [X1_test,X2_test,X3_test,X4_test,X5_test,X6_test,X7_test,X8_test,X9_test,X10_test]
y_test_cross = [y1_test,y2_test,y3_test,y4_test,y5_test,y6_test,y7_test,y8_test,y9_test,y10_test]

hidden1 = [8,15,30,58]
hidden2 = [8,15,30,58]
nhidden1 = len(hidden1)
nhidden2 = len(hidden2)
ncross = len(X_train_cross)
err = list()
acc = list()

for c in range(ncross):
    print("dataset (1-10)", c)
    set_train_X = X_train_cross[c]
    set_train_y = y_train_cross [c]
    set_test_X = X_test_cross [c]
    set_test_y = y_test_cross[c]
    for i in range(nhidden1):
        N1 = hidden1[i]
        print("N1",N1)
        for j in range(nhidden2):
            N2 = hidden2[j]
            classifier = models.Sequential()
            classifier.add(layers.Dense(output_dim = 15, init = 'uniform', input_dim = 15, activation = 'relu'))
            classifier.add(layers.Dense(output_dim = N1, init = 'uniform',activation = 'relu'))
            classifier.add(layers.Dense(output_dim = N2, init='uniform', activation = 'relu'))
            classifier.add(layers.Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
            classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])
            history = classifier.fit(set_train_X, set_train_y, batch_size = 100, nb_epoch = 11)
            err.append(history.history['loss'][10])
            acc.append(history.history['acc'][10])
print(err)
print(acc)
